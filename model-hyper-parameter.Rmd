---
layout: page
title: xwMOOC 모형
subtitle: "초모수 미세조정(Hyper Parameter Tuning)"
author:
    name: xwMOOC
    url: https://www.facebook.com/groups/tidyverse/
    affiliation: Tidyverse Korea
date: "`r Sys.Date()`"
output:
  html_document: 
    toc: yes
    toc_float: true
    highlight: tango
    code_folding: show
    number_section: true
    self_contained: true
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE,
                      comment="", digits = 3, tidy = FALSE, prompt = FALSE, fig.align = 'center')

```


# 모수와 초모수 {#hyper-parameter}

모수(parameter)는 예측모형을 데이터를 통해 훈련시키면서 찾게되는데 흔히 회귀계수(regression coefficient)로 쉽게 이해될 수 있으며,
초모수(Hyperparameter)는 데이터를 통해 훈련시키기 전에 사전에 설정된다는 점에서 차이가 있다.

- 선형 회귀모형에서 회귀 계수, 기계학습에서 weigths, bias가 대표적.
- 기계학습에서 학습율(learning rate), Random Forest에서 나무 갯수, `mtry` 등을 들 수 있다.

# 예측모형 프레임워크 {#framework-predictive-model}

R의 대표적인 예측모형 프레임워크로 다음 3개를 많이 사용한다.
3가지 프레임워크 모두 서로 추구하는 바가 뿌렸하여 본인 업무에 가장 적합한 것을 확인해서 사용한다.

- [caret](https://cran.r-project.org/web/packages/caret/vignettes/caret.html)
- [$H_2 O$](https://www.h2o.ai/)
- [mrl](https://mlr.mlr-org.com/)

# 예측모형 초모수 {#framework-predictive-model-hyper-parameter}

[caret](https://cran.r-project.org/web/packages/caret/vignettes/caret.html),
[$H_2 O$](https://www.h2o.ai/), [mrl](https://mlr.mlr-org.com/) 예측모형 프레임워크 모두 다음 세가지 사항을 지정해야만 된다.

1. 초모수 검색공간(search space): `mtry`, 활성화 함수 등
1. 재표집 방법(resampling method)
1. 미세조정 방법: 격자 검색(grid search), 무작위 검색(random search), Adaptive Resampling 등


초모수 검색공간 즉, 초모수 설정 대상은 [caret - 예측모형 사전](https://topepo.github.io/caret/available-models.html) 사이트에서 
"Tuning Parameters"를 통해 각 예측모형별로 검색하여 지정하면된다.
예를 들어 Random Forest 모형의 대표적인 팩키지 `ranger`의 경우 미세조정 초모수는 `mtry`, `splitrule`, `min.node.size`가 된다.
유사한 방식으로 예측모형에 적용할 모형을 [caret - 예측모형 사전](https://topepo.github.io/caret/available-models.html) 사이트에서 
찾아 `Tuning Parameters`를 보고 확인하여 지정하면 된다.

| Model         | `method` Value | Type                       | Libraries             | Tuning Parameters              |
|---------------|----------------|----------------------------|-----------------------|--------------------------------|
| Random Forest |  ranger        | Classification, Regression | e1071, ranger, dplyr  | mtry, splitrule, min.node.size |
|Stochastic Gradient Boosting | gbm | Classification, Regression | gbm, plyr   n.trees, interaction.depth, shrinkage, n.minobsinnode |

재표집 방법은 `caret`의 경우 `trainControl`을 통해 설정한다. `repeatedcv` 방법으로 10 조각을 내서 표본을 추출해서 각각 예측모형 접합을 시키고 
이를 총 5회 반복한다. 재표집 방법은 `repeatedcv`외에서 `? trainControl` 명령어를 통해서 
 "boot", "boot632", "optimism_boot", "boot_all", "cv", "repeatedcv", "LOOCV", 
 "LGOCV", "none", "oob", timeslice, "adaptive_cv", "adaptive_boot", "adaptive_LGOCV" 등 다양하게 설정할 수 있다.

``` {r hyperparameter-resampling, eval=FALSE}
fitControl <- trainControl(method = "repeatedcv",
                           number = 10,
                           repeats = 5)
```                           

미세조정 방법은 격자 검색(grid search), 무작위 검색(random search), Adaptive Resampling 3가지를 `caret`에서 지정하는데 
최적 초모수 조합을 찾아내는 것은 동일하다고 볼 수 있으나 최적 초모수 조합을 찾는 효율성의 측면에서는 Adaptive Resampling이 
더 낫다고 볼 수 있다.


# 예측모형 - `caret` {#framework-predictive-model-hyper-parameter-caret}

예측모형 개발을 위해서 데이터를 불러오고 이를 `janitor` 팩키지로 칼럼명을 깔끔히 정리하고 특히 정보가 매우 적은 변수는 `nearZeroVar()` 함수로 전처리 단계에서 제거한다.
그리고 나서, 훈련/시험 데이터로 나누고, 멀티코어를 활용하여 훈련시간을 단축시키기 위해서 클러스터를 구축한다.

```{r predictive-model-caret}
library(tidyverse)
library(caret)
library(tictoc)
library(janitor)
library(doSNOW)

# 1. 데이터 ------
data(GermanCredit)

# 2. 데이터 전처리 ------
## 변수명 정리 -----
credit_dat <- GermanCredit %>% 
  clean_names() %>% 
  tbl_df

## 예측모형에 사용되는 변수정리 -----
all_variables <- names(credit_dat)
remove_variables <- names(credit_dat)[nearZeroVar(credit_dat)]

credit_df <- credit_dat[ , setdiff(all_variables, remove_variables)]

# 3. 예측모형 ------
## 3.1. 훈련 vs 검증/시험
train_test_index <- createDataPartition(credit_df$class, p = 0.7, list = FALSE)

train <- credit_df[train_test_index, ]
test <- credit_df[-train_test_index, ]
```

## 격자탐색(grid search) {#framework-predictive-model-hyper-parameter-caret-grid}

`tictoc` 팩키지를 통해 `tic()`, `toc()` 함수로 모형 훈련시간을 측정하고 
교차검증(cross validation)을 위해서 `k=3`, `repeats=1`로 설정한다. 
앞서 [caret - 예측모형 사전](https://topepo.github.io/caret/available-models.html)에서 검색한 `ranger` 팩키지 초모수를 찾아 `expand.grid`를 통해 격자 탐색 공간을 설정한다.

예를 들어 `mtry = 48`, `splitrule = extratrees`, `min.node.size = 10` 초모수가 선정되고 이에 해당되는 모형 성능도 나타나게 된다.

```{r predictive-model-caret-grid}
## 3.2. 병렬처리 환경설정
num_cores <- parallel:::detectCores()
tic()

cl <- makeCluster(num_cores, type = "SOCK")
registerDoSNOW(cl)

## 3.3. 모형 개발/검증 데이터셋 준비 ------
cv_folds <- createMultiFolds(train$class, k = 3, times = 1)

fit_ctrl <- trainControl(method = "repeatedcv", 
                        number = 3,
                        repeats = 1,
                        index = cv_folds, 
                        summaryFunction = twoClassSummary,
                        classProbs = TRUE, # 매우 중요
                        verboseIter = TRUE)

ranger_tune_grid <- expand.grid(
  .mtry = c(2,25,48),
  .splitrule = c("gini","extratrees"),
  .min.node.size = 10
)

## 3.2. 예측모형 적용
### ranger
gc_grid_ranger_model <- train(class ~., train,
                  method = "ranger",
                  metric = "Sens",
                  preProcess = c("zv", "center", "scale", "spatialSign"),
                  tuneGrid = ranger_tune_grid,
                  # tuneLength = 7,
                  trControl = fit_ctrl)

# 4. 모형 비교평가-----
gc_grid_ranger_model

toc()
```

## 무작위  검색 (random search) {#framework-predictive-model-hyper-parameter-caret-random}

무작위 검색(random search)은 `trainControl()` 함수에 `search = "random"`을 지정하고 
실무에서 `tuneLength = 100`와 같은 값을 지정하게 되면 
`caret` 팩키지 `train()` 함수에서 선택한 예측모형 `ranger`의 초모수를 찾아 각 모수별로 100개 난수값을 발생시켜 모형을 적합시켜 최고 성능을 내는 조합을 찾아준다.

```{r predictive-model-caret-random}
tic()
## 3.3. 모형 개발/검증 데이터셋 준비 ------
cv_folds <- createMultiFolds(train$class, k = 3, times = 1)

fit_ctrl <- trainControl(method = "repeatedcv", 
                        number = 3,
                        repeats = 1,
                        index = cv_folds, 
                        search = "random",
                        summaryFunction = twoClassSummary,
                        classProbs = TRUE, # 매우 중요
                        verboseIter = TRUE)

## 3.2. 예측모형 적용
### ranger
gc_ranger_model <- train(class ~., train,
                  method = "ranger",
                  metric = "Sens",
                  preProcess = c("zv", "center", "scale", "spatialSign"),
                  trControl = fit_ctrl,
                  tuneLength = 7)

# 4. 모형 비교평가-----
gc_ranger_model

stopCluster(cl)
toc()
```


## 적응 재표집 (adaptive resampling) {#framework-predictive-model-hyper-parameter-caret-adaptive}

무작위 검색 방법과 유사하고 다만 `trainControl()`에 `method="adaptive_cv"`를 지정하고,
`adaptive=`에 인자값을 지정하면 된다. 적응 재표집에 대한 자세한 사항은 [Max Kuhn (2014), "Futility Analysis in the Cross-Validation of Machine Learning Models"](https://arxiv.org/abs/1405.6974)를 참조한다.

```{r predictive-model-caret-adaptive, eval=FALSE}
tic()
## 3.3. 모형 개발/검증 데이터셋 준비 ------
cv_folds <- createMultiFolds(train$class, k = 3, times = 1)

fit_ctrl <- trainControl(method = "adaptive_cv", 
                        number = 3,
                        repeats = 1,
                        index = cv_folds, 
                        search = "random",
                        adaptive = list(min = 3, alpha = 0.05, method = "BT", complete = FALSE),
                        summaryFunction = twoClassSummary,
                        classProbs = TRUE, # 매우 중요
                        verboseIter = TRUE)

## 3.2. 예측모형 적용
### ranger
gc_ranger_model <- train(class ~., train,
                  method = "ranger",
                  metric = "Sens",
                  preProcess = c("zv", "center", "scale", "spatialSign"),
                  trControl = fit_ctrl,
                  tuneLength = 7)

# 4. 모형 비교평가-----
gc_ranger_model

toc()
```

# 초모수 모형 성능 평가 {#framework-predictive-model-hyper-parameter-evaluation}

`caret` 예측모형 객체를 `plot`, `ggplot` 함수에 넣으면 시각화를 통해 최적의 초모수를 선정하는데 도움이 된다. 다르게 설정된 초모수 조합이 모형 성능에 어떤 영향을 주는지를 초모수 모형성능 평가를 통해서 확인할 수 있고 특히 어떤 초모수가 예측모형 성능에 크고 작은 영향을 미치는지도 이해할 수 있다. 물론 초모수 공간에 수렴하는지 파악하여 최적 초모수 조합(Optimal Hyperparameter Combinatin)을 발견하는데 단초를 제공한다.

``` {r hyper-parameter-evaluation}
ggplot(gc_grid_ranger_model)
```

`Kappa` 값을 시각화하여 높은 `Kappa` 값을 통해 추가로 탐색할 수 있는 초모수 공간에 대한 힌트를 얻을 수도 있다.

``` {r hyper-parameter-evaluation-kappa, eval=FALSE}
plot(gc_grid_ranger_model,
     metric = "Kappa",
     plotType = "level")
```


